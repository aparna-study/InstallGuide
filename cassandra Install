Procedure

Suppose you install Cassandra on these nodes:

Note: It is a best practice to have more than one seed node per data center.
If you have a firewall running in your cluster, you must open certain ports for communication between the nodes. See Configuring firewall port access.
If Cassandra is running, you must stop the server and clear the data:
Doing this removes the default cluster_name (Test Cluster) from the system table. All nodes must use the same cluster name.

Package installations:

Stop Cassandra:
$ sudo service cassandra stop
Clear the data:
$ sudo rm -rf /var/lib/cassandra/data/system/*
Tarball installations:

Stop Cassandra:
$ ps auwx | grep cassandra
$ sudo  kill pid
Clear the data:
$ sudo rm -rf /var/lib/cassandra/data/system/*
Set the properties in the cassandra.yaml file for each node:
Package installations: /etc/cassandra/cassandra.yaml
Note: After making any changes in the cassandra.yaml file, you must restart the node for the changes to take effect.
Properties to set:
num_tokens: recommended value: 256
-seeds: internal IP address of each seed node
Seed nodes do not bootstrap, which is the process of a new node joining an existing cluster. For new clusters, the bootstrap process on seed nodes is skipped.

listen_address:
If not set, Cassandra asks the system for the local address, the one associated with its hostname. In some cases Cassandra doesn't produce the correct address and you must specify the listen_address.

endpoint_snitch: name of snitch (See endpoint_snitch.) If you are changing snitches, see Switching snitches.
auto_bootstrap: false (Add this setting only when initializing a fresh cluster with no data.)
Note: If the nodes in the cluster are identical in terms of disk layout, shared libraries, and so on, you can use the same copy of the cassandra.yaml file on all of them.
Example:

cluster_name: 'MyCassandraCluster'
num_tokens: 256
seed_provider:
  - class_name: org.apache.cassandra.locator.SimpleSeedProvider
    parameters:
         - seeds: "host address you want as seed node"
listen_address:
rpc_address: 0.0.0.0
endpoint_snitch: GossipingPropertyFileSnitch

and uncomment brodcast_rpc_address:1.2.3.4
In the cassandra-rackdc.properties file, assign the data center and rack names you determined in the Prerequisites. For example:
# indicate the rack and dc for this node
dc=DC1
rack=RAC1
After you have installed and configured Cassandra on all nodes, start the seed nodes one at a time, and then start the rest of the nodes.
Note: If the node has restarted because of automatic restart, you must first stop the node and clear the data directories, as described above.
Package installations:

$ sudo service cassandra start

[root@snn2 ~]#
[root@snn2 ~]# nodetool status test
Datacenter: datacenter1
=======================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
-- Address Load Tokens Owns (effective) Host ID Rack
UN 192.168.1.164 2.97 MB 256 67.7% cf7edb7e-3861-45ee-8257-d64bced00f76 rack1
UN 192.168.1.165 1.7 MB 256 67.0% f2adf886-8170-4fbc-ae2b-2cbf582d9793 rack1
UN 192.168.1.168 3.08 MB 256 65.3% 052ac5b4-dc64-4606-82c3-b502245ee3e7 rack1


when we want it to install cassandra on multiple datacenters

1] we change property file {1st add seed node as one of the seed node from previous Datacenter}
2]Change endpoint_snitch in yaml from SimpleSnitch to PropertyFileSnitch
3]Restart Cassandra 
4] Alter keyspace
cqlsh> ALTER KEYSPACE test WITH REPLICATION = { 'class' : 'NetworkTopologyStrategy', 'DC1' : 3, 'DC2' : 1};

5] now check the status for that keyspace 
[root@snn2 ~]# nodetool status test
Datacenter: DC1
===============
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
-- Address Load Tokens Owns (effective) Host ID Rack
UN 192.168.1.164 4.02 MB 256 100.0% cf7edb7e-3861-45ee-8257-d64bced00f76 r1
UN 192.168.1.165 2.68 MB 256 100.0% f2adf886-8170-4fbc-ae2b-2cbf582d9793 RAC1
UN 192.168.1.168 3.98 MB 256 100.0% 052ac5b4-dc64-4606-82c3-b502245ee3e7 RAC1
Datacenter: DC2
===============
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
-- Address Load Tokens Owns (effective) Host ID Rack
UN 192.168.1.161 1.56 MB 256 100.0% ffeab04e-6459-40de-b239-befceccfd578 RAC1


once you are able to see the result you can change the seed node of second datacenter in yaml file

6] And the way to confirm on datacenter 2 node that data is present you can use local_quorum consistency








